{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/train.csv\", encoding = \"ISO-8859-1\", names=['polarity', 'id', 'query', 'user', 'text'], index_col=2)\n",
    "df = df.sample(frac=1)[:60_000] # shuffle and truncate\n",
    "df['polarity'] = df['polarity'].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "tdf, vdf = train_test_split(df, test_size=0.2)\n",
    "train_data = tdf['text'].to_numpy()\n",
    "train_label = tdf['polarity'].to_numpy()\n",
    "\n",
    "val_data = vdf['text'].to_numpy()\n",
    "val_label = vdf['polarity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 200_000  # full vocab for 1.6M dataset contains 850061 tokens\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'i', 'to', 'the', 'a', 'my', 'and', 'you', 'is', 'it',\n",
       "       'in', 'for', 'of', 'im', 'on', 'me', 'so', 'have', 'that', 'just',\n",
       "       'but', 'with', 'be', 'its', 'at', 'not', 'was', 'this', 'good',\n",
       "       'up', 'now', 'get', 'out', 'day', 'all', 'are', 'go', 'like', 'no'],\n",
       "      dtype='<U112')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "word_index = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "print(len(vocab))\n",
    "vocab[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([467, 848,   4, 297,  42])>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(\"Hello, how's the weather today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = \"glove/glove.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 27946 words (36172 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(vocab)\n",
    "embedding_dim = 200\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    "    mask_zero=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_layer(encoder('I am'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 45 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fec699f1870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[-0.69028836]\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "[-0.69028854]\n"
     ]
    }
   ],
   "source": [
    "sample_text = ('the gig last night turned out great')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])\n",
    "\n",
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 61s 35ms/step - loss: 0.5290 - accuracy: 0.7062 - val_loss: 0.4921 - val_accuracy: 0.7502\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 63s 42ms/step - loss: 0.4690 - accuracy: 0.7630 - val_loss: 0.4817 - val_accuracy: 0.7437\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 0.4545 - accuracy: 0.7734 - val_loss: 0.4697 - val_accuracy: 0.7595\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 53s 35ms/step - loss: 0.4445 - accuracy: 0.7788 - val_loss: 0.4653 - val_accuracy: 0.7621\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 57s 38ms/step - loss: 0.4357 - accuracy: 0.7860 - val_loss: 0.4614 - val_accuracy: 0.7717\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 54s 36ms/step - loss: 0.4276 - accuracy: 0.7910 - val_loss: 0.4569 - val_accuracy: 0.7682\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 62s 41ms/step - loss: 0.4194 - accuracy: 0.7960 - val_loss: 0.4551 - val_accuracy: 0.7777\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 0.4116 - accuracy: 0.8022 - val_loss: 0.4581 - val_accuracy: 0.7786\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 62s 41ms/step - loss: 0.4031 - accuracy: 0.8064 - val_loss: 0.4520 - val_accuracy: 0.7780\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 54s 36ms/step - loss: 0.3952 - accuracy: 0.8128 - val_loss: 0.4538 - val_accuracy: 0.7761\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=train_data, y=train_label, validation_data=(val_data, val_label), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.5173236 ],\n",
       "       [-2.7038252 ],\n",
       "       [-0.32582322],\n",
       "       [-3.0155642 ],\n",
       "       [ 3.6182864 ],\n",
       "       [ 3.0159233 ],\n",
       "       [ 2.916467  ],\n",
       "       [ 1.1423533 ],\n",
       "       [ 1.2402942 ],\n",
       "       [ 1.9487635 ]], dtype=float32)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([\"Shit!\", \"Oh fuck!\", \"You'd better shut up!\", \"I wanna kill this bastard\", \"That was amazing\", \"OMG!\"\n",
    "                        \"That was cute\", \"Nice one\", \"I loved it\", \"I really liked how he behaved\", \"He was a nice dude\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
