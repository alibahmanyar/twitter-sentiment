{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sentiment 140:\n",
      "{0, 4}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "\n",
    "map_polarity = {0:0, 4:2, 2:1}\n",
    "\n",
    "def map_model_out(x):\n",
    "    if x < 0.5:\n",
    "        return 0\n",
    "    elif x > 0.5:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "print(\"\\n\\nSentiment 140:\")\n",
    "df = pd.read_csv(\"../trainModel/datasets/test.csv\", encoding = \"ISO-8859-1\", names=['polarity', 'id', 'query', 'user', 'text'], index_col=2)\n",
    "df = df.sample(frac=1)[:] # shuffle and truncate\n",
    "df.drop(df.loc[df['polarity']==2].index, inplace=True)\n",
    "print(set(df['polarity'].values))\n",
    "\n",
    "# real_labels = df['polarity'].map(lambda x: map_polarity[x])\n",
    "df['polarity'] = df['polarity'].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "test_data = df['text'].to_numpy()\n",
    "test_label = df['polarity'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 15:44:32.544957: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_text_vectorization_input:0', 'index': 0, 'shape': array([1], dtype=int32), 'shape_signature': array([-1], dtype=int32), 'dtype': <class 'numpy.bytes_'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}] \n",
      " [{'name': 'StatefulPartitionedCall_2:0', 'index': 125, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Time Warner cable is down again 3rd time since Memorial Day bummer!\n",
      "0 -4.18075\n",
      "1 -1.0766909\n",
      "2 9.65689\n",
      "3 -1.3482693\n",
      "4 1.2517375\n",
      "5 -5.209608\n",
      "6 -0.59262097\n",
      "7 -4.0717134\n",
      "8 4.1789546\n",
      "9 -0.8836008\n",
      "10 -4.6240764\n",
      "11 -2.808138\n",
      "12 3.6600041\n",
      "13 4.524804\n",
      "14 -0.22586496\n",
      "15 -2.5888495\n",
      "16 2.3799229\n",
      "17 4.307381\n",
      "18 -2.6877818\n",
      "19 -2.6937554\n",
      "20 -3.3980248\n",
      "21 -0.931443\n",
      "22 2.2008257\n",
      "23 3.483005\n",
      "24 3.9056964\n",
      "25 0.042852122\n",
      "26 3.2309132\n",
      "27 -3.649727\n",
      "28 -0.8691428\n",
      "29 0.9055772\n",
      "30 -4.4732237\n",
      "31 4.2393975\n",
      "32 -1.5182369\n",
      "33 3.4769442\n",
      "34 3.6468537\n",
      "35 -0.92565936\n",
      "36 3.858025\n",
      "37 -3.7567117\n",
      "38 4.911943\n",
      "39 1.3802984\n",
      "40 -0.89782506\n",
      "41 -0.62312114\n",
      "42 0.21498941\n",
      "43 0.3042827\n",
      "44 2.1344166\n",
      "45 -0.38046858\n",
      "46 -4.2587366\n",
      "47 0.11180349\n",
      "48 2.7591062\n",
      "49 4.9656234\n",
      "50 2.2937264\n",
      "51 2.4149978\n",
      "52 0.8137882\n",
      "53 5.878163\n",
      "54 -1.5808659\n",
      "55 2.804655\n",
      "56 -1.2325257\n",
      "57 3.6415634\n",
      "58 -2.644939\n",
      "59 -4.0131874\n",
      "60 1.3192778\n",
      "61 0.29114732\n",
      "62 1.232451\n",
      "63 -1.240553\n",
      "64 10.958358\n",
      "65 -3.1959233\n",
      "66 0.9328939\n",
      "67 2.5148647\n",
      "68 -0.219285\n",
      "69 3.0650892\n",
      "70 0.26761284\n",
      "71 5.5295405\n",
      "72 -2.3409274\n",
      "73 4.5394325\n",
      "74 0.81918573\n",
      "75 1.1593211\n",
      "76 4.1072607\n",
      "77 1.5140862\n",
      "78 4.9390826\n",
      "79 3.861551\n",
      "80 1.868494\n",
      "81 5.338741\n",
      "82 -1.1038897\n",
      "83 -4.142342\n",
      "84 -2.4176192\n",
      "85 0.32066002\n",
      "86 -4.105434\n",
      "87 -4.966909\n",
      "88 0.21725138\n",
      "89 -1.9038676\n",
      "90 0.48933616\n",
      "91 6.8110566\n",
      "92 3.5360167\n",
      "93 1.3755085\n",
      "94 -4.674948\n",
      "95 -1.29844\n",
      "96 -2.0851583\n",
      "97 -3.2190275\n",
      "98 -1.318334\n",
      "99 -0.45528415\n",
      "100 5.2695155\n",
      "101 -2.4379935\n",
      "102 -2.978821\n",
      "103 -3.5344443\n",
      "104 -1.687639\n",
      "105 4.6503654\n",
      "106 1.9668725\n",
      "107 -0.7545415\n",
      "108 -1.1306775\n",
      "109 -0.19693811\n",
      "110 2.504711\n",
      "111 -2.572456\n",
      "112 -2.5592346\n",
      "113 -0.3467169\n",
      "114 -3.9437823\n",
      "115 4.783832\n",
      "116 2.2062724\n",
      "117 -1.0246906\n",
      "118 1.8941258\n",
      "119 -3.4101334\n",
      "120 -1.7969402\n",
      "121 3.5464296\n",
      "122 0.72644144\n",
      "123 2.1086128\n",
      "124 1.0049511\n",
      "125 -1.4951004\n",
      "126 0.5892575\n",
      "127 -0.06504677\n",
      "128 0.17482431\n",
      "129 -3.6945858\n",
      "130 0.08663811\n",
      "131 4.2083464\n",
      "132 0.5579842\n",
      "133 -3.3572865\n",
      "134 3.0696099\n",
      "135 -2.416737\n",
      "136 -1.7460558\n",
      "137 -3.6775656\n",
      "138 -1.4763951\n",
      "139 -4.3932524\n",
      "140 4.6985817\n",
      "141 0.6048542\n",
      "142 -3.6656961\n",
      "143 0.17020334\n",
      "144 -2.5323334\n",
      "145 5.2998824\n",
      "146 1.1422627\n",
      "147 5.6228676\n",
      "148 -0.28725183\n",
      "149 1.736913\n",
      "150 -3.7506003\n",
      "151 5.996878\n",
      "152 -2.8115706\n",
      "153 -1.8801999\n",
      "154 -2.7748692\n",
      "155 -2.4701204\n",
      "156 1.3054445\n",
      "157 -5.7307763\n",
      "158 -1.4606662\n",
      "159 -0.7297186\n",
      "160 -1.0679069\n",
      "161 3.657441\n",
      "162 1.6901518\n",
      "163 1.5030311\n",
      "164 -2.2786105\n",
      "165 -1.5303994\n",
      "166 1.4209367\n",
      "167 -0.090707466\n",
      "168 -2.6506207\n",
      "169 -3.3442297\n",
      "170 -1.1102043\n",
      "171 3.3563685\n",
      "172 -0.83677405\n",
      "173 -1.1993628\n",
      "174 -1.9543304\n",
      "175 -1.9538498\n",
      "176 1.0041368\n",
      "177 6.5806174\n",
      "178 -4.0998797\n",
      "179 -4.897714\n",
      "180 5.5094676\n",
      "181 6.0831733\n",
      "182 3.5220017\n",
      "183 3.4352672\n",
      "184 2.4861445\n",
      "185 2.079722\n",
      "186 -2.906689\n",
      "187 1.9889011\n",
      "188 -0.14043146\n",
      "189 4.059686\n",
      "190 0.40796104\n",
      "191 5.893128\n",
      "192 0.8614577\n",
      "193 -3.6638923\n",
      "194 0.07115723\n",
      "195 -2.896298\n",
      "196 2.4629931\n",
      "197 -1.7421405\n",
      "198 2.4292269\n",
      "199 2.2135708\n",
      "200 -2.2889988\n",
      "201 2.680913\n",
      "202 -1.2834067\n",
      "203 2.6096232\n",
      "204 3.0905497\n",
      "205 -0.44960865\n",
      "206 -0.3440209\n",
      "207 4.7753844\n",
      "208 -1.5940776\n",
      "209 -2.1977582\n",
      "210 1.0454148\n",
      "211 1.6507965\n",
      "212 0.0003268905\n",
      "213 0.55673385\n",
      "214 0.48596886\n",
      "215 4.4326777\n",
      "216 -2.276371\n",
      "217 -0.67522156\n",
      "218 -1.2386172\n",
      "219 -0.9075533\n",
      "220 3.805842\n",
      "221 3.4259145\n",
      "222 2.7686615\n",
      "223 7.7369466\n",
      "224 4.9022565\n",
      "225 -1.2641406\n",
      "226 0.24095394\n",
      "227 -2.0080943\n",
      "228 3.896894\n",
      "229 0.3522705\n",
      "230 1.8304337\n",
      "231 2.5495114\n",
      "232 5.061462\n",
      "233 5.439778\n",
      "234 2.4748604\n",
      "235 3.3127153\n",
      "236 2.796948\n",
      "237 -0.46372136\n",
      "238 4.0152707\n",
      "239 -1.5544505\n",
      "240 0.24590935\n",
      "241 -0.6093273\n",
      "242 5.622314\n",
      "243 4.8922467\n",
      "244 5.0815034\n",
      "245 1.9737517\n",
      "246 3.371133\n",
      "247 -1.4330771\n",
      "248 3.623603\n",
      "249 -1.653695\n",
      "250 8.5445175\n",
      "251 4.1208873\n",
      "252 4.2255692\n",
      "253 3.8760033\n",
      "254 -3.3641853\n",
      "255 -1.2973175\n",
      "256 -0.15962039\n",
      "257 -0.21224271\n",
      "258 -0.5697049\n",
      "259 1.4515278\n",
      "260 0.12340562\n",
      "261 -2.0929356\n",
      "262 1.3633437\n",
      "263 2.7288952\n",
      "264 1.9065019\n",
      "265 -1.52545\n",
      "266 -4.3120904\n",
      "267 -1.1797814\n",
      "268 -2.137839\n",
      "269 5.273764\n",
      "270 -0.29497957\n",
      "271 -2.0323737\n",
      "272 7.8157973\n",
      "273 -3.8101623\n",
      "274 0.6813686\n",
      "275 5.2741904\n",
      "276 2.427102\n",
      "277 1.2653233\n",
      "278 7.1031575\n",
      "279 8.19231\n",
      "280 1.101255\n",
      "281 6.0179315\n",
      "282 4.798723\n",
      "283 3.4446013\n",
      "284 0.69305176\n",
      "285 -4.9674387\n",
      "286 1.3875344\n",
      "287 -2.7879272\n",
      "288 0.43385231\n",
      "289 -3.0438166\n",
      "290 1.0228119\n",
      "291 5.1679406\n",
      "292 1.133239\n",
      "293 -7.366663\n",
      "294 3.5283232\n",
      "295 0.9084034\n",
      "296 1.4746621\n",
      "297 -4.302958\n",
      "298 1.879804\n",
      "299 6.072106\n",
      "300 -0.64797986\n",
      "301 -2.4960396\n",
      "302 0.009299774\n",
      "303 0.7281657\n",
      "304 10.635633\n",
      "305 0.643176\n",
      "306 -2.1621723\n",
      "307 5.138512\n",
      "308 2.5576634\n",
      "309 5.1932077\n",
      "310 -4.6500096\n",
      "311 0.16201772\n",
      "312 -2.1497006\n",
      "313 -0.053872686\n",
      "314 4.4966273\n",
      "315 0.9953494\n",
      "316 1.1310014\n",
      "317 -0.060147148\n",
      "318 1.5705302\n",
      "319 -1.2598355\n",
      "320 -3.2836251\n",
      "321 3.6872966\n",
      "322 2.0288508\n",
      "323 4.8317566\n",
      "324 1.0984511\n",
      "325 1.0422263\n",
      "326 4.4586115\n",
      "327 -2.9677572\n",
      "328 1.3641864\n",
      "329 -0.49720076\n",
      "330 -1.5276129\n",
      "331 6.21856\n",
      "332 -2.5535648\n",
      "333 -1.0877727\n",
      "334 1.2219133\n",
      "335 1.2762313\n",
      "336 -1.8115885\n",
      "337 -4.259302\n",
      "338 -2.7164528\n",
      "339 -0.06906249\n",
      "340 1.6209624\n",
      "341 0.9487939\n",
      "342 3.775698\n",
      "343 3.588004\n",
      "344 -0.04609869\n",
      "345 3.2867372\n",
      "346 2.6810074\n",
      "347 1.5225811\n",
      "348 -1.7819911\n",
      "349 7.639153\n",
      "350 1.0120572\n",
      "351 4.1065326\n",
      "352 -1.0181291\n",
      "353 2.2983057\n",
      "354 -0.6113193\n",
      "355 -3.640832\n",
      "356 -3.4525585\n",
      "357 -0.8129378\n",
      "358 -0.19031765\n",
      "[[144  33]\n",
      " [ 37 145]]\n",
      "0.8050139275766016\n"
     ]
    }
   ],
   "source": [
    "with open(\"web-test/model.tflite\", 'rb') as f :\n",
    "    interpreter = tf.lite.Interpreter(model_content=f.read())\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "print(interpreter.get_input_details(),'\\n', interpreter.get_output_details())\n",
    "\n",
    "print(test_data[0])\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for i, t in enumerate(test_data):\n",
    "    interpreter.set_tensor(input_index, np.array([t]))\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.tensor(output_index)\n",
    "    predictions.append(output()[0][0])\n",
    "    print(i, predictions[-1])\n",
    "\n",
    "predictions = [map_model_out(x) for x in predictions]\n",
    "\n",
    "print(sklearn.metrics.confusion_matrix(test_label, predictions))\n",
    "print(list(predictions - test_label).count(0) / len(predictions))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
